import streamlit as st
import pandas as pd
import json
import uuid
from backend_codes import build_workflow
from langchain_core.messages import HumanMessage, AIMessage

# --- 1. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æº–å‚™ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã®ã¿ï¼‰ ---
# @st.cache_resourceã‚’ä½¿ã†ã“ã¨ã§ã€ã‚¢ãƒ—ãƒªã®å†å®Ÿè¡Œæ™‚ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å†æ§‹ç¯‰ã™ã‚‹ã®ã‚’é˜²ãã€é«˜é€ŸåŒ–ã—ã¾ã™ã€‚
@st.cache_resource
def get_workflow():
    return build_workflow()

compiled_workflow = get_workflow()

# --- 2. Streamlitãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š ---
st.title("ğŸ¤– ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ£ãƒƒãƒˆAI")
st.caption("ã“ã®AIã¯ã€è£å´ã§LangGraphã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

# -ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è‡ªå‰ã§ç®¡ç†ã™ã‚‹å ´åˆ
if "session_id" not in st.session_state:
    st.session_state["session_id"] = str(uuid.uuid4())

# --- 4. éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã™ã¹ã¦è¡¨ç¤º ---
# st.session_state.messagesã«ã¯ã€{"role": "user", "content": ...} ã‚„ {"role": "assistant", "content": ...} ã®å½¢å¼ã§ä¿å­˜
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # contentãŒæ–‡å­—åˆ—ã®å ´åˆï¼ˆé€šå¸¸ã®ä¼šè©±ï¼‰
        if isinstance(message["content"], str):
            st.markdown(message["content"])
        # contentãŒè¾æ›¸ã®å ´åˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚„ã‚°ãƒ©ãƒ•ã‚’å«ã‚€ï¼‰
        elif isinstance(message["content"], dict):
            if "result_df_json" in message["content"] and message["content"]["result_df_json"]:
                df_data = json.loads(message["content"]["result_df_json"])
                st.dataframe(pd.DataFrame(df_data))
            if "fig_json" in message["content"] and message["content"]["fig_json"]:
                fig = pd.io.json.read_json(message["content"]["fig_json"], typ='frame')
                st.plotly_chart(fig)
            if "interpretation" in message["content"] and message["content"]["interpretation"]:
                 st.markdown(message["content"]["interpretation"])


# --- 5. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ ---
# ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã¾ã‚‹ã”ã¨ç½®ãæ›ãˆã¾ã™
# -------------------------------------------------------------------------

user_input = st.chat_input("åˆ†æã—ãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šã‚’è¦‹ã›ã¦ï¼‰")

if user_input:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
    with st.chat_message("assistant"):

        # st.spinnerã®ä»£ã‚ã‚Šã«st.statusã‚’ä½¿ç”¨ã€‚å®Ÿè¡ŒçŠ¶æ³ã‚’å‹•çš„ã«æ›´æ–°ã§ãã‚‹
        with st.status("AIãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æä¸­...", expanded=True) as status:
            
            # LangGraphãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®å‘¼ã³å‡ºã—è¨­å®š
            config = {"configurable": {"thread_id": st.session_state.session_id}}
            input_data = {"messages": [HumanMessage(content=user_input)]}
            
            # æœ€çµ‚çš„ã«è¡¨ç¤ºã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿æŒã™ã‚‹å¤‰æ•°
            final_content = None

            # .invoke()ã®ä»£ã‚ã‚Šã«.stream()ã‚’ä½¿ã„ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
            for chunk in compiled_workflow.stream(input_data, config):
                
                # --- chunkã‚’è§£æã—ã¦ã€å®Ÿè¡ŒçŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º ---
                if "supervisor" in chunk:
                    # ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ãŒæ€è€ƒä¸­
                    status.update(label="ã©ã®å°‚é–€å®¶ã«ä¾é ¼ã™ã‚‹ã‹æ€è€ƒä¸­...")
                elif "sql_node" in chunk:
                    # SQLãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                    status.update(label="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€SQLã‚’å®Ÿè¡Œä¸­...")
                elif "processing_node" in chunk:
                    # ãƒ‡ãƒ¼ã‚¿åŠ å·¥/ã‚°ãƒ©ãƒ•ä½œæˆãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                    status.update(label="ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã—ã€ã‚°ãƒ©ãƒ•ã‚’ä½œæˆä¸­...")
                elif "interpret_node" in chunk:
                    # è§£é‡ˆãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                    status.update(label="çµæœã‚’è§£é‡ˆã—ã€èª¬æ˜ã‚’ç”Ÿæˆä¸­...")

                # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®æœ€å¾Œã«ã¯ã€æœ€çµ‚çŠ¶æ…‹ãŒ'__end__'ã‚­ãƒ¼ã§å«ã¾ã‚Œã‚‹
                if "__end__" in chunk:
                    final_state = chunk["__end__"]
                    final_content = final_state["messages"][-1]
            
            # --- æœ€çµ‚çš„ãªå¿œç­”ã‚’è§£æã—ã¦è¡¨ç¤º ---

            # statusã‚’ã€Œå®Œäº†ã€çŠ¶æ…‹ã«æ›´æ–°
            status.update(label="åˆ†æå®Œäº†ï¼", state="complete", expanded=False)
            
            # è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
            display_content = {}
            
            # è¿”ç­”ã®å½¢å¼ã«å¿œã˜ã¦å†…å®¹ã‚’è§£æ
            if isinstance(final_content, AIMessage):
                # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”
                display_content["interpretation"] = final_content.content
                st.markdown(display_content["interpretation"])

            elif hasattr(final_content, 'content') and isinstance(final_content.content, str):
                try:
                    # JSONå½¢å¼ã®æ–‡å­—åˆ—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚„ã‚°ãƒ©ãƒ•ï¼‰
                    parsed_content = json.loads(final_content.content)
                    
                    if parsed_content.get("result_df_json"):
                        df_data = json.loads(parsed_content["result_df_json"])
                        display_content["result_df_json"] = parsed_content["result_df_json"]
                        st.dataframe(pd.DataFrame(df_data))
                    
                    if parsed_content.get("fig_json"):
                        # ã“ã“ã§ã¯ç›´æ¥è¡¨ç¤ºã€‚å±¥æ­´ä¿å­˜ç”¨ã«fig_jsonã‚‚ä¿æŒ
                        fig = pd.io.json.read_json(parsed_content["fig_json"], typ='frame')
                        display_content["fig_json"] = parsed_content["fig_json"]
                        st.plotly_chart(fig)

                except json.JSONDecodeError:
                    # JSONã§ã¯ãªã„ãŸã ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”
                    display_content["interpretation"] = final_content.content
                    st.markdown(display_content["interpretation"])

            # è§£æã—ãŸAIã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
            if display_content:
                st.session_state.messages.append({"role": "assistant", "content": display_content})
