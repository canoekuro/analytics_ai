import streamlit as st
import pandas as pd
import json
import uuid
from backend_codes import build_workflow
from langchain_core.messages import HumanMessage, AIMessage
import logging

logger = logging.getLogger("langgraph")
logger.setLevel(logging.DEBUG)

# --- 1. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æº–å‚™ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã®ã¿ï¼‰ ---
# @st.cache_resourceã‚’ä½¿ã†ã“ã¨ã§ã€ã‚¢ãƒ—ãƒªã®å†å®Ÿè¡Œæ™‚ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å†æ§‹ç¯‰ã™ã‚‹ã®ã‚’é˜²ãã€é«˜é€ŸåŒ–ã—ã¾ã™ã€‚
@st.cache_resource
def get_workflow():
    return build_workflow()

compiled_workflow = get_workflow()

# --- 2. Streamlitãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š ---
st.title("ğŸ¤– ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ£ãƒƒãƒˆAI")
st.caption("ã“ã®AIã¯ã€è£å´ã§LangGraphã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

# -ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è‡ªå‰ã§ç®¡ç†ã™ã‚‹å ´åˆ
if "session_id" not in st.session_state:
    st.session_state["session_id"] = str(uuid.uuid4())

# --- 4. éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã™ã¹ã¦è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # contentãŒæ–‡å­—åˆ—ã®å ´åˆï¼ˆé€šå¸¸ã®ä¼šè©±ï¼‰
        if isinstance(message["content"], str):
            st.markdown(message["content"])
        # contentãŒè¾æ›¸ã®å ´åˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚„ã‚°ãƒ©ãƒ•ã‚’å«ã‚€ï¼‰
        elif isinstance(message["content"], dict):
            if "result_df_json" in message["content"] and message["content"]["result_df_json"]:
                df_data = json.loads(message["content"]["result_df_json"])
                st.dataframe(pd.DataFrame(df_data))
            if "fig_json" in message["content"] and message["content"]["fig_json"]:
                fig = pd.io.json.read_json(message["content"]["fig_json"], typ='frame')
                st.plotly_chart(fig)
            if "interpretation" in message["content"] and message["content"]["interpretation"]:
                 st.markdown(message["content"]["interpretation"])


# --- 5. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ ---
user_input = st.chat_input("åˆ†æã—ãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šã‚’è¦‹ã›ã¦ï¼‰")

if user_input:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # AIã®å¿œç­”ã‚’å¾…ã¤é–“ã€ã‚¹ãƒ”ãƒŠãƒ¼ï¼ˆãã‚‹ãã‚‹å›ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ï¼‰ã‚’è¡¨ç¤º
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿
    with st.chat_message("assistant"):
        
        # st.spinnerã®ä»£ã‚ã‚Šã«st.statusã‚’ä½¿ç”¨ã€‚å®Ÿè¡ŒçŠ¶æ³ã‚’å‹•çš„ã«æ›´æ–°ã§ãã‚‹
        with st.status("AIãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æä¸­...", expanded=True) as status:
            try:
                # LangGraphãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®å‘¼ã³å‡ºã—è¨­å®š
                config = {"configurable": {"thread_id": st.session_state.session_id}}
                input_data = {"messages": [HumanMessage(content=user_input)]}
                
                # .invoke()ã®ä»£ã‚ã‚Šã«.stream()ã‚’ä½¿ã„ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
                for chunk in compiled_workflow.stream(input_data, config, stream_mode="updates"):
                    
                    # --- chunkã‚’è§£æã—ã¦ã€å®Ÿè¡ŒçŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º ---
                    if "supervisor" in chunk:
                        # ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ãŒæ€è€ƒä¸­
                        status.update(label=f"ã©ã®å°‚é–€å®¶ã«ä¾é ¼ã™ã‚‹ã‹æ€è€ƒä¸­...")
                    elif "tools" in chunk:
                        status.update(label=f"ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ä¸­...")
                    elif "sql_node" in chunk:
                        # SQLãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                        status.update(label="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€SQLã‚’å®Ÿè¡Œä¸­...")
                    elif "processing_node" in chunk:
                        # ãƒ‡ãƒ¼ã‚¿åŠ å·¥/ã‚°ãƒ©ãƒ•ä½œæˆãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                        status.update(label="ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã—ã€ã‚°ãƒ©ãƒ•ã‚’ä½œæˆä¸­...")
                    elif "interpret_node" in chunk:
                        # è§£é‡ˆãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œä¸­
                        status.update(label="çµæœã‚’è§£é‡ˆã—ã€èª¬æ˜ã‚’ç”Ÿæˆä¸­...")
                    else:
                        status.update(label="å°‘ã€…ãŠå¾…ã¡ãã ã•ã„...")

                status.update(label="åˆ†æå®Œäº†ï¼", state="complete", expanded=False)
                ai_response = chunk["supervisor"]["messages"][0]
                response_content = None

                # è¿”ç­”ã®å½¢å¼ã«å¿œã˜ã¦å†…å®¹ã‚’è§£æ
                if isinstance(ai_response, AIMessage):
                    # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”
                    response_content = ai_response.content

                else:
                    response_content = "AIå¿œç­”ã®æœ€çµ‚çŠ¶æ…‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

                # è§£æã—ãŸAIã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": response_content})             
                # ç”»é¢ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã€æœ€æ–°ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
                st.rerun()

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
